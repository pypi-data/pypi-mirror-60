{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hs2 objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hs2 import HSDetection, HSClustering\n",
    "from probe import NeuroSeeker_128\n",
    "\n",
    "\n",
    "data_path = '../datasets/TEST_HIGHPASS_INVERTED_PIP_Kampff_2015_09_03_Pair_9_0.hdf5'\n",
    "\n",
    "Probe = NeuroSeeker_128(data_file_path=data_path)\n",
    "\n",
    "\n",
    "default_detection_parameters = {'to_localize': True,\n",
    "                                  'cutout_start': 10,\n",
    "                                  'cutout_end': 30,\n",
    "                                  'threshold': 130,\n",
    "                                  'maa': 0,\n",
    "                                  'maxsl': 12,\n",
    "                                  'minsl': 3,\n",
    "                                  'ahpthr': 0\n",
    "                                }\n",
    "\n",
    "HSD = HSDetection(Probe, **default_detection_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GT spiketrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimisation class expects ground-truth as a numpy array of timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = '../datasets/HIGHPASS_INVERTED_PIP_Kampff_2015_09_03_Pair_9_0_Thresh_15_SpikesSYCL.txt'\n",
    "\n",
    "gt_spiketrain = np.loadtxt(gt_path, dtype='int')[:,1]\n",
    "\n",
    "closest_ch = 109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise both detection and clustering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameter_optimisation import OptimiseParameters\n",
    "\n",
    "# Define parameters to optimise over\n",
    "detec_params_to_opt = {'threshold': (50, 300),\n",
    "                       'ahpthr': (0, 20),\n",
    "                       'maxsl': (0, 30)\n",
    "                       }\n",
    "\n",
    "clust_params_to_opt = {'bandwidth': (0., 4.),\n",
    "                       'alpha': (0., 5.),\n",
    "                       'pca_ncomponents': (1, 10)\n",
    "                       }\n",
    "\n",
    "detect_results_name = 'result_optim_params_detect' \n",
    "clust_results_name = 'result_optim_params_clust' \n",
    "\n",
    "op = OptimiseParameters(gt_spiketrain,\n",
    "                        closest_ch, \n",
    "                        Probe,\n",
    "                        HSD, \n",
    "                        detec_params_to_opt, \n",
    "                        None, \n",
    "                        clust_params_to_opt, \n",
    "                        optimise_detection=True, \n",
    "                        optimise_clustering=True,\n",
    "                        detec_run_schedule=(5,1),\n",
    "                        clust_run_schedule=(5,1),\n",
    "                        detec_outfile=detect_results_name, \n",
    "                        clust_outfile=clust_results_name)\n",
    "\n",
    "HSC = op.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = ''\n",
    "with open('{}{}.pickle'.format(results_path,detect_results_name), 'rb') as f:\n",
    "    results_obj = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skopt.plots import plot_convergence, plot_evaluations, plot_objective\n",
    "\n",
    "parameter_names = list(detec_params_to_opt.keys())\n",
    "\n",
    "plt.figure(figsize=(15,3.5))\n",
    "plot_convergence(results_obj, ax=plt.gca());\n",
    "plot_evaluations(results_obj, dimensions=parameter_names);\n",
    "plot_objective(results_obj, dimensions=parameter_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(obj, title):\n",
    "    plt.figure(figsize=(17,3))\n",
    "    \n",
    "    TPs = np.asarray(list(map(len, obj['TPs']))).reshape(32,4)\n",
    "    FNs = np.asarray(list(map(len, obj['FNs'])))\n",
    "    \n",
    "    plt.imshow(np.transpose(TPs), cmap='jet', interpolation='bilinear')\n",
    "    for i,FN in enumerate(FNs):\n",
    "        color = 'w' # if i is 116 else 'w'\n",
    "        color = 'magenta' if i is 109 else color\n",
    "        plt.text(i//4, i%4, FN, \n",
    "                 color=color, \n",
    "                 fontsize=10 if FN>10**3 else 12, \n",
    "                 horizontalalignment='center')\n",
    "    plt.title('Missed detections on each channel.', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_heatmap(results_obj, 'Missed detections per channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count duplicate spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_count = HSD.spikes.shape[0]\n",
    "duplicate_count = 0\n",
    "for ch in tqdm(range(128), desc='Deduplication', unit=' channels'):\n",
    "    # Select all in neighbourhood\n",
    "    neigh_spikes = HSD.spikes.loc[HSD.spikes['ch'].isin(Probe.neighbors[ch])]\n",
    "    \n",
    "    # Count duplicated timestamps in neighbourhood\n",
    "    if len(neigh_spikes) > 0:\n",
    "        duplicate_count += np.sum(neigh_spikes.t.duplicated())\n",
    "\n",
    "print(\"Found {} ({:.2f}%) duplicate spikes.\".format(duplicate_count, 100*duplicate_count/orig_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually inspect detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_lim = 0\n",
    "upper_lim = 2*10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_raw = Probe.Read(lower_lim, upper_lim).reshape(-1, 128)\n",
    "# in case there weren't enough frames in probe file\n",
    "upper_lim = min(upper_lim, probe_raw.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probes.readUtils import readNeuroSeekerPipette\n",
    "\n",
    "gt_raw = readNeuroSeekerPipette(h5py.File(data_path), lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "ch = closest_ch\n",
    "\n",
    "ch_spiketrain = HSD.spikes.loc[HSD.spikes['ch'] == ch]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "n_frames = upper_lim - lower_lim\n",
    "xs = np.arange(n_frames)\n",
    "\n",
    "# plt.xlim(200000, 300000)\n",
    "plt.ylim(-4000, 6000)\n",
    "plt.title(\"Channel {}\".format(ch))\n",
    "plt.xlabel(\"Frames\")\n",
    "plt.ylabel(\"Voltage (arbitrary units)\")\n",
    "\n",
    "# Graphs the signal on that channel\n",
    "plt.plot(xs, probe_raw[lower_lim:upper_lim, ch], zorder=1, color='grey')\n",
    "\n",
    "# # Graphs all spikes detected on channel ch from channels\n",
    "trim_spikes_probe = ch_spiketrain[(lower_lim < ch_spiketrain.t) & (ch_spiketrain.t < upper_lim)]\n",
    "plt.scatter(trim_spikes_probe.t, probe_raw[:, ch][trim_spikes_probe.t], zorder=2, color='r', marker='o')\n",
    "\n",
    "# Plot pipette as well\n",
    "scale_gt = 5\n",
    "shift_gt = +0\n",
    "plt.plot(xs, gt_raw[lower_lim:upper_lim]*scale_gt + shift_gt, zorder=0, color='lightgrey')\n",
    "trim_spikes_pip = gt_spiketrain[np.logical_and([lower_lim < gt_spiketrain], [gt_spiketrain < upper_lim])[0]]\n",
    "plt.scatter(trim_spikes_pip, gt_raw[trim_spikes_pip]*scale_gt + shift_gt, zorder=3, color='lightsalmon', marker='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_results_path = ''\n",
    "\n",
    "with open('{}{}.pickle'.format(clust_results_path, clust_results_name), 'rb') as f:\n",
    "    clust_results = pickle.load(f)\n",
    "\n",
    "c = clust_results['most_popular_cluster']\n",
    "alpha = clust_results['clustering_parameters']['alpha']\n",
    "bandw = clust_results['clustering_parameters']['bandwidth']\n",
    "n_PCA = clust_results['clustering_parameters']['n_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most popular cluster={} | alpha={} | bandwidth={} | nPCA={}'.format(c, alpha, bandw, n_PCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,3.5))\n",
    "plot_convergence(clust_results, ax=plt.gca());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ch = closest_ch\n",
    "gt = clust_results['Ps']\n",
    "sp = HSC.spikes[HSC.spikes['ch'].isin(Probe.neighbors[ch])]\n",
    "y_lim = (24.5, 29.5)\n",
    "x_lim = (0,4)\n",
    "\n",
    "# Filter out different groups of spikes\n",
    "mask =  HSC.spikes['ch'].isin(Probe.neighbors[ch]) & HSC.spikes['t'].isin(gt)\n",
    "gt_sp = HSC.spikes[mask]\n",
    "mask =  HSC.spikes['ch'].isin(Probe.neighbors[ch]) & HSC.spikes['t'].isin(gt) & (HSC.spikes['cl']==c)\n",
    "tp_sp = HSC.spikes[mask]\n",
    "mask =  HSC.spikes['ch'].isin(Probe.neighbors[ch]) & ~HSC.spikes['t'].isin(gt) & (HSC.spikes['cl']==c)\n",
    "fp_sp = HSC.spikes[mask]\n",
    "\n",
    "# Generate title strings\n",
    "titles = ['All neighbour.\\nspikes (n={})'.format(sp.shape[0]),\n",
    "          'GT spikes\\n(n={})'.format(gt_sp.shape[0]),\n",
    "          'TPs (n={})'.format(len(tp_sp)),\n",
    "          'FPs (n={})'.format(len(fp_sp))\n",
    "         ]\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.xlim(*x_lim)\n",
    "    plt.ylim(*y_lim)\n",
    "    plt.scatter(sp.x, sp.y, marker='+', color='green', s=5., alpha=0.8)\n",
    "    if i>0:\n",
    "        plt.scatter(gt_sp.x, gt_sp.y, marker='+', color='r', s=5., alpha=0.8)\n",
    "    if i==2:\n",
    "        plt.scatter(tp_sp.x, tp_sp.y, marker='+', color='blue', s=5., alpha=0.8)\n",
    "    if i==3:\n",
    "        plt.scatter(fp_sp.x, fp_sp.y, marker='+', color='yellow', s=5., alpha=0.8)\n",
    "    plt.title(title, fontsize=24);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSC.PlotNeighbourhood(cl=c, radius=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "HSC.PlotShapes([c], nshapes=1000, ax=plt.gca())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
