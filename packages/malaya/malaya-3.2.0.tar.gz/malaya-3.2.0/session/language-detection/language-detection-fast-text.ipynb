{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def clean_text(string):\n",
    "    string = re.sub(u'[0-9!@#$%^&*()_\\-+{}|\\~`\\'\";:?/.>,<]', ' ', string.lower(), flags=re.UNICODE)\n",
    "    return re.sub(r'[ ]+', ' ', string.lower()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('language-detection-data-v5.json','r') as fopen:\n",
    "    loaded = json.load(fopen)\n",
    "    sentences = [clean_text(text) for text in loaded['text']]\n",
    "    langs = loaded['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('language-detection-vectorizer.pkl','rb') as fopen:\n",
    "    bow_chars = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 124 ms, total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target = LabelEncoder().fit_transform(langs)\n",
    "features = bow_chars.transform(sentences)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(features, target, test_size = 0.2)\n",
    "del features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166343, 660726)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sparse_matrix_to_sparse_tensor(X, limit = 5):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    coo.data[coo.data > limit] = limit\n",
    "    return tf.SparseTensorValue(indices, coo.col, coo.shape), tf.SparseTensorValue(indices, coo.data, coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.X = tf.sparse_placeholder(tf.int32)\n",
    "        self.W = tf.sparse_placeholder(tf.int32)\n",
    "        self.Y = tf.placeholder(tf.int32, [None])\n",
    "        embeddings = tf.Variable(tf.truncated_normal([train_X.shape[1],40]))\n",
    "        embed = tf.nn.embedding_lookup_sparse(embeddings, self.X, self.W, combiner='mean')\n",
    "        self.logits = tf.layers.dense(embed, 4)\n",
    "        self.cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits = self.logits, labels = self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.cost)\n",
    "        correct_pred = tf.equal(tf.argmax(self.logits, 1,output_type=tf.int32), self.Y)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = Model(1e-4)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lang-detection-w/model.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'lang-detection-w/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Placeholder_2',\n",
       " 'Placeholder_3',\n",
       " 'Placeholder_4',\n",
       " 'Placeholder_5',\n",
       " 'Placeholder_6',\n",
       " 'Variable',\n",
       " 'dense/kernel',\n",
       " 'dense/bias']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name)\n",
    "        and 'Adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(660726, 40) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(40, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.00it/s, accuracy=0.857, cost=0.732]\n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.46it/s, accuracy=0.94, cost=0.558] \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.75it/s, accuracy=0.75, cost=0.814] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.36624956130981\n",
      "epoch: 0, training loss: 1.042807, training acc: 0.739603, valid loss: nan, valid acc: 0.870874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.05it/s, accuracy=1, cost=0.309]    \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.62it/s, accuracy=0.98, cost=0.204] \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.88it/s, accuracy=0.891, cost=0.442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.26686263084412\n",
      "epoch: 1, training loss: 0.420440, training acc: 0.917406, valid loss: nan, valid acc: 0.951756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.09it/s, accuracy=1, cost=0.144]     \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.66it/s, accuracy=0.98, cost=0.0981] \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.91it/s, accuracy=0.953, cost=0.275]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.24010252952576\n",
      "epoch: 2, training loss: 0.196528, training acc: 0.970849, valid loss: nan, valid acc: 0.979674\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 32.97it/s, accuracy=1, cost=0.0669]    \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 210.46it/s, accuracy=1, cost=0.0534]    \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.74it/s, accuracy=0.953, cost=0.193] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.17026662826538\n",
      "epoch: 3, training loss: 0.105076, training acc: 0.985867, valid loss: nan, valid acc: 0.987784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.01it/s, accuracy=1, cost=0.0318]    \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.34it/s, accuracy=1, cost=0.0312]    \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.96it/s, accuracy=0.953, cost=0.151] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.29047513008118\n",
      "epoch: 4, training loss: 0.062966, training acc: 0.990598, valid loss: nan, valid acc: 0.991103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 32.93it/s, accuracy=1, cost=0.0163]    \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.20it/s, accuracy=1, cost=0.0194]    \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.92it/s, accuracy=0.953, cost=0.125] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.23359727859497\n",
      "epoch: 5, training loss: 0.042258, training acc: 0.993159, valid loss: nan, valid acc: 0.993051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.00it/s, accuracy=1, cost=0.00904]   \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 212.27it/s, accuracy=1, cost=0.0128]    \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.87it/s, accuracy=0.969, cost=0.108] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.21385073661804\n",
      "epoch: 6, training loss: 0.030973, training acc: 0.994511, valid loss: nan, valid acc: 0.994036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.08it/s, accuracy=1, cost=0.00537]   \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 211.77it/s, accuracy=1, cost=0.00886]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.82it/s, accuracy=0.969, cost=0.0947]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.13079595565796\n",
      "epoch: 7, training loss: 0.024160, training acc: 0.995479, valid loss: nan, valid acc: 0.994878\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 32.97it/s, accuracy=1, cost=0.00337]   \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 212.59it/s, accuracy=1, cost=0.00643]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.87it/s, accuracy=0.969, cost=0.0848]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.28797364234924\n",
      "epoch: 8, training loss: 0.019677, training acc: 0.996183, valid loss: nan, valid acc: 0.995527\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.04it/s, accuracy=1, cost=0.00221]   \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 214.02it/s, accuracy=1, cost=0.00483]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.86it/s, accuracy=0.969, cost=0.0769]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.11047410964966\n",
      "epoch: 9, training loss: 0.016514, training acc: 0.996748, valid loss: nan, valid acc: 0.995864\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.02it/s, accuracy=1, cost=0.0015]    \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 213.58it/s, accuracy=1, cost=0.00375]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 33.02it/s, accuracy=0.969, cost=0.0705]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.07126927375793\n",
      "epoch: 10, training loss: 0.014159, training acc: 0.997277, valid loss: nan, valid acc: 0.996080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 32.91it/s, accuracy=1, cost=0.00104]   \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 212.99it/s, accuracy=1, cost=0.00298]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.82it/s, accuracy=0.969, cost=0.0651]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.13535642623901\n",
      "epoch: 11, training loss: 0.012330, training acc: 0.997601, valid loss: nan, valid acc: 0.996417\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.03it/s, accuracy=1, cost=0.000745]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 214.46it/s, accuracy=1, cost=0.00241]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.89it/s, accuracy=0.969, cost=0.0605]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.07676434516907\n",
      "epoch: 12, training loss: 0.010864, training acc: 0.997842, valid loss: nan, valid acc: 0.996802\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.11it/s, accuracy=1, cost=0.000542]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:02<00:00, 216.87it/s, accuracy=1, cost=0.00199]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 33.09it/s, accuracy=0.969, cost=0.0565]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.01633334159851\n",
      "epoch: 13, training loss: 0.009658, training acc: 0.998100, valid loss: nan, valid acc: 0.996874\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:18<00:00, 33.13it/s, accuracy=1, cost=0.000401]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 214.32it/s, accuracy=1, cost=0.00167]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.94it/s, accuracy=0.984, cost=0.053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 81.9391098022461\n",
      "epoch: 14, training loss: 0.008647, training acc: 0.998317, valid loss: nan, valid acc: 0.996970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 32.96it/s, accuracy=1, cost=0.000301]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 215.30it/s, accuracy=1, cost=0.00142]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.95it/s, accuracy=0.984, cost=0.0498]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.04596328735352\n",
      "epoch: 15, training loss: 0.007786, training acc: 0.998563, valid loss: nan, valid acc: 0.997066\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:18<00:00, 33.06it/s, accuracy=1, cost=0.000229]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 215.03it/s, accuracy=1, cost=0.00122]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 32.87it/s, accuracy=0.984, cost=0.0469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 81.97728490829468\n",
      "epoch: 16, training loss: 0.007043, training acc: 0.998707, valid loss: nan, valid acc: 0.997211\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.06it/s, accuracy=1, cost=0.000176]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 214.48it/s, accuracy=1, cost=0.00106]   \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:19, 32.84it/s, accuracy=0.984, cost=0.0442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.04397535324097\n",
      "epoch: 17, training loss: 0.006396, training acc: 0.998828, valid loss: nan, valid acc: 0.997283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.05it/s, accuracy=1, cost=0.000138]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 215.15it/s, accuracy=1, cost=0.000927]  \n",
      "train minibatch loop:   0%|          | 4/2600 [00:00<01:18, 33.01it/s, accuracy=0.984, cost=0.0417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.10938167572021\n",
      "epoch: 18, training loss: 0.005828, training acc: 0.999002, valid loss: nan, valid acc: 0.997331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train minibatch loop: 100%|██████████| 2600/2600 [01:19<00:00, 33.10it/s, accuracy=1, cost=0.000109]  \n",
      "test minibatch loop: 100%|██████████| 650/650 [00:03<00:00, 214.98it/s, accuracy=1, cost=0.000821]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken: 82.04319453239441\n",
      "epoch: 19, training loss: 0.005327, training acc: 0.999152, valid loss: nan, valid acc: 0.997475\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "for e in range(20):\n",
    "    lasttime = time.time()\n",
    "    train_acc, train_loss, test_acc, test_loss = 0, 0, 0, 0\n",
    "    pbar = tqdm(\n",
    "        range(0, train_X.shape[0], batch_size), desc = 'train minibatch loop'\n",
    "    )\n",
    "    for i in pbar:\n",
    "        batch_x = convert_sparse_matrix_to_sparse_tensor(train_X[i : min(i + batch_size, train_X.shape[0])])\n",
    "        batch_y = train_Y[i : min(i + batch_size, train_X.shape[0])]\n",
    "        acc, cost, _ = sess.run(\n",
    "            [model.accuracy, model.cost, model.optimizer],\n",
    "            feed_dict = {\n",
    "                model.X: batch_x[0],\n",
    "                model.W: batch_x[1],\n",
    "                model.Y: batch_y\n",
    "            },\n",
    "        )\n",
    "        assert not np.isnan(cost)\n",
    "        train_loss += cost\n",
    "        train_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    pbar = tqdm(range(0, test_X.shape[0], batch_size), desc = 'test minibatch loop')\n",
    "    for i in pbar:\n",
    "        batch_x = convert_sparse_matrix_to_sparse_tensor(test_X[i : min(i + batch_size, test_X.shape[0])])\n",
    "        batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])]\n",
    "        batch_x_expand = np.expand_dims(batch_x,axis = 1)\n",
    "        acc, cost = sess.run(\n",
    "            [model.accuracy, model.cost],\n",
    "            feed_dict = {\n",
    "                model.X: batch_x[0],\n",
    "                model.W: batch_x[1],\n",
    "                model.Y: batch_y\n",
    "            },\n",
    "        )\n",
    "        test_loss += cost\n",
    "        test_acc += acc\n",
    "        pbar.set_postfix(cost = cost, accuracy = acc)\n",
    "\n",
    "    train_loss /= train_X.shape[0] / batch_size\n",
    "    train_acc /= train_X.shape[0] / batch_size\n",
    "    test_loss /= test_X.shape[0] / batch_size\n",
    "    test_acc /= test_X.shape[0] / batch_size\n",
    "\n",
    "    print('time taken:', time.time() - lasttime)\n",
    "    print(\n",
    "        'epoch: %d, training loss: %f, training acc: %f, valid loss: %f, valid acc: %f\\n'\n",
    "        % (e, train_loss, train_acc, test_loss, test_acc)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "validation minibatch loop:   0%|          | 0/650 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:   3%|▎         | 21/650 [00:00<00:03, 205.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:   8%|▊         | 51/650 [00:00<00:02, 225.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  13%|█▎        | 83/650 [00:00<00:02, 246.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  18%|█▊        | 115/650 [00:00<00:02, 262.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  23%|██▎       | 147/650 [00:00<00:01, 275.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  27%|██▋       | 178/650 [00:00<00:01, 281.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  32%|███▏      | 210/650 [00:00<00:01, 291.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  37%|███▋      | 241/650 [00:00<00:01, 295.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  42%|████▏     | 272/650 [00:00<00:01, 297.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  47%|████▋     | 305/650 [00:01<00:01, 304.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  52%|█████▏    | 337/650 [00:01<00:01, 307.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  57%|█████▋    | 368/650 [00:01<00:00, 306.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  61%|██████▏   | 399/650 [00:01<00:00, 307.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  66%|██████▋   | 432/650 [00:01<00:00, 311.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  71%|███████▏  | 464/650 [00:01<00:00, 307.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  76%|███████▌  | 495/650 [00:01<00:00, 305.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  81%|████████  | 526/650 [00:01<00:00, 302.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  86%|████████▌ | 557/650 [00:01<00:00, 296.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  90%|█████████ | 588/650 [00:01<00:00, 299.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop:  95%|█████████▌| 619/650 [00:02<00:00, 302.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "validation minibatch loop: 100%|██████████| 650/650 [00:02<00:00, 301.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "real_Y, predict_Y = [], []\n",
    "\n",
    "pbar = tqdm(\n",
    "    range(0, test_X.shape[0], batch_size), desc = 'validation minibatch loop'\n",
    ")\n",
    "for i in pbar:\n",
    "    batch_x = convert_sparse_matrix_to_sparse_tensor(test_X[i : min(i + batch_size, test_X.shape[0])])\n",
    "    batch_y = test_Y[i : min(i + batch_size, test_X.shape[0])].tolist()\n",
    "    predict_Y += np.argmax(\n",
    "        sess.run(\n",
    "            model.logits, feed_dict = {model.X: batch_x[0], model.W: batch_x[1], model.Y: batch_y}\n",
    "        ),\n",
    "        1,\n",
    "    ).tolist()\n",
    "    real_Y += batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       1.00      0.99      0.99      9445\n",
      "     english       1.00      1.00      1.00      9987\n",
      "  indonesian       1.00      1.00      1.00     11518\n",
      "       malay       1.00      1.00      1.00     10636\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     41586\n",
      "   macro avg       1.00      1.00      1.00     41586\n",
      "weighted avg       1.00      1.00      1.00     41586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    metrics.classification_report(\n",
    "        real_Y, predict_Y, target_names = ['other','english','indonesian','malay']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_text = '今天是６月１８号，也是Muiriel的生日！'\n",
    "english_text = 'i totally love it man'\n",
    "indon_text = 'menjabat saleh perombakan menjabat periode komisi energi fraksi partai pengurus partai periode periode partai terpilih periode menjabat komisi perdagangan investasi persatuan periode'\n",
    "malay_text = 'beliau berkata program Inisitif Peduli Rakyat (IPR) yang diperkenalkan oleh kerajaan negeri Selangor lebih besar sumbangannya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = bow_chars.transform([chinese_text,english_text,indon_text,malay_text])\n",
    "batch_x = convert_sparse_matrix_to_sparse_tensor(transformed)\n",
    "np.argmax(sess.run(model.logits, feed_dict = {model.X: batch_x[0], model.W: batch_x[1]}),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166343, 660726)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lang-detection-w/model.ckpt'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'lang-detection-w/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
