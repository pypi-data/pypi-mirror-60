{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_train.txt') as fopen:\n",
    "    y = fopen.read().split('\\n')\n",
    "    \n",
    "with open('x_train.txt') as fopen:\n",
    "    x = fopen.read().split('\\n')\n",
    "    \n",
    "with open('y_test.txt') as fopen:\n",
    "    y.extend(fopen.read().split('\\n'))\n",
    "    \n",
    "with open('x_test.txt') as fopen:\n",
    "    x.extend(fopen.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Klement Gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>est</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sebes, Joseph; Pereira Thomas (1961) (på eng)....</td>\n",
       "      <td>swe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...</td>\n",
       "      <td>mai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Après lo cort periòde d'establiment a Basilèa,...</td>\n",
       "      <td>oci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...</td>\n",
       "      <td>tha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text lang\n",
       "0  Klement Gottwaldi surnukeha palsameeriti ning ...  est\n",
       "1  Sebes, Joseph; Pereira Thomas (1961) (på eng)....  swe\n",
       "2  भारतीय स्वातन्त्र्य आन्दोलन राष्ट्रीय एवम क्षे...  mai\n",
       "3  Après lo cort periòde d'establiment a Basilèa,...  oci\n",
       "4  ถนนเจริญกรุง (อักษรโรมัน: Thanon Charoen Krung...  tha"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'text':x,'lang':y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = df.loc[df.lang.isin(['msa','ind'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def augmenter(text,label):\n",
    "    label = 'zlm' if label == 'msa' else label\n",
    "    text = text.split()\n",
    "    half = len(text) // 2\n",
    "    t = []\n",
    "    for i in range(len(text) - (half //2)):\n",
    "        t.append(' '.join(text[i:i + half]))\n",
    "    return t, [label] * len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for i in range(selected.shape[0]):\n",
    "    x, y = augmenter(selected.iloc[i,0],selected.iloc[i,1])\n",
    "    X.extend(x)\n",
    "    Y.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>cmn</th>\n",
       "      <th>我們試試看！</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>cmn</td>\n",
       "      <td>我该去睡觉了。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>cmn</td>\n",
       "      <td>你在干什麼啊？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>cmn</td>\n",
       "      <td>這是什麼啊？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>cmn</td>\n",
       "      <td>今天是６月１８号，也是Muiriel的生日！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>cmn</td>\n",
       "      <td>生日快乐，Muiriel！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  cmn                  我們試試看！\n",
       "0  2  cmn                 我该去睡觉了。\n",
       "1  3  cmn                 你在干什麼啊？\n",
       "2  4  cmn                  這是什麼啊？\n",
       "3  5  cmn  今天是６月１８号，也是Muiriel的生日！\n",
       "4  6  cmn           生日快乐，Muiriel！"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang = pd.read_csv('sentences.csv',sep='\\t')\n",
    "lang = lang.dropna()\n",
    "lang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['eng', 'tur', 'rus', 'ita', 'epo', 'deu', 'fra', 'por', 'spa', 'hun',\n",
       "       'heb', 'jpn', 'ukr', 'ber', 'pol', 'fin', 'mkd', 'nld', 'cmn', 'mar',\n",
       "       'dan', 'swe', 'srp', 'lat', 'ara', 'ell', 'ces', 'bul', 'lit', 'toki'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang.cmn.value_counts().index[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_langs = ['zlm','eng','ind']\n",
    "special_langs = ['tur', 'rus', 'ita', 'epo', 'deu', 'fra', 'por', 'spa', 'hun',\n",
    "       'heb', 'jpn', 'ukr', 'ber', 'pol', 'fin', 'mkd', 'nld', 'cmn', 'mar',\n",
    "       'dan', 'swe', 'srp', 'lat', 'ara', 'ell', 'ces', 'bul', 'lit', 'toki','kor','fil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vie\n",
      "arz\n",
      "yue\n",
      "bel\n",
      "que\n",
      "swh\n",
      "nno\n",
      "wuu\n",
      "nob\n",
      "zsm\n",
      "est\n",
      "kat\n",
      "urd\n",
      "sqi\n",
      "isl\n",
      "fry\n",
      "afr\n",
      "ron\n",
      "fao\n",
      "san\n",
      "bre\n",
      "tat\n",
      "yid\n",
      "uig\n",
      "uzb\n",
      "qya\n",
      "pes\n",
      "slk\n",
      "eus\n",
      "cycl\n",
      "acm\n",
      "tgl\n",
      "lvs\n",
      "kaz\n",
      "hye\n",
      "hin\n",
      "ben\n",
      "cat\n",
      "bos\n",
      "hrv\n",
      "tha\n",
      "orv\n",
      "cha\n",
      "mon\n",
      "lzh\n",
      "scn\n",
      "gle\n",
      "slv\n",
      "frm\n",
      "glg\n",
      "vol\n",
      "ain\n",
      "jbo\n",
      "ina\n",
      "nds\n",
      "mal\n",
      "tlh\n",
      "roh\n",
      "ltz\n",
      "oss\n",
      "ido\n",
      "gla\n",
      "mlt\n",
      "sco\n",
      "ast\n",
      "jav\n",
      "oci\n",
      "ile\n",
      "xal\n",
      "tel\n",
      "sjn\n",
      "nov\n",
      "khm\n",
      "tpi\n",
      "ang\n",
      "aze\n",
      "tgk\n",
      "tuk\n",
      "chv\n",
      "hsb\n",
      "dsb\n",
      "bod\n",
      "sme\n",
      "cym\n",
      "mri\n",
      "ksh\n",
      "kur\n",
      "ewe\n",
      "kab\n",
      "tpw\n",
      "udm\n",
      "lld\n",
      "pms\n",
      "lad\n",
      "grn\n",
      "mlg\n",
      "xho\n",
      "pnb\n",
      "grc\n",
      "hat\n",
      "lao\n",
      "npi\n",
      "cor\n",
      "nah\n",
      "avk\n",
      "guj\n",
      "pan\n",
      "kir\n",
      "myv\n",
      "prg\n",
      "sux\n",
      "crs\n",
      "ckt\n",
      "bak\n",
      "hil\n",
      "cbk\n",
      "chr\n",
      "nav\n",
      "lkt\n",
      "enm\n",
      "arq\n",
      "lin\n",
      "abk\n",
      "pcd\n",
      "rom\n",
      "gsw\n",
      "tam\n",
      "zul\n",
      "awa\n",
      "wln\n",
      "amh\n",
      "bar\n",
      "ota\n",
      "mhr\n",
      "bho\n",
      "mrj\n",
      "osx\n",
      "pfl\n",
      "mgm\n",
      "sna\n",
      "mah\n",
      "hau\n",
      "kan\n",
      "nog\n",
      "sin\n",
      "glv\n",
      "dng\n",
      "kal\n",
      "liv\n",
      "vro\n",
      "apc\n",
      "jdt\n",
      "fur\n",
      "che\n",
      "haw\n",
      "yor\n",
      "crh\n",
      "pdc\n",
      "ppl\n",
      "kin\n",
      "shs\n",
      "mnw\n",
      "tet\n",
      "sah\n",
      "kum\n",
      "ngt\n",
      "nya\n",
      "pus\n",
      "hif\n",
      "mya\n",
      "moh\n",
      "wol\n",
      "tir\n",
      "lzz\n",
      "oar\n",
      "lug\n",
      "brx\n",
      "non\n",
      "mww\n",
      "hak\n",
      "nlv\n",
      "ngu\n",
      "bua\n",
      "aym\n",
      "vec\n",
      "ibo\n",
      "tkl\n",
      "ton\n",
      "bam\n",
      "kha\n",
      "ceb\n",
      "lou\n",
      "fuc\n",
      "smo\n",
      "gag\n",
      "lfn\n",
      "arg\n",
      "umb\n",
      "tyv\n",
      "kjh\n",
      "oji\n",
      "cyo\n",
      "urh\n",
      "kzj\n",
      "pam\n",
      "srd\n",
      "lmo\n",
      "swg\n",
      "mdf\n",
      "gil\n",
      "snd\n",
      "tso\n",
      "sot\n",
      "zza\n",
      "tsn\n",
      "pau\n",
      "som\n",
      "egl\n",
      "ady\n",
      "asm\n",
      "ori\n",
      "dtp\n",
      "cho\n",
      "max\n",
      "kam\n",
      "niu\n",
      "sag\n",
      "ilo\n",
      "kaa\n",
      "fuv\n",
      "nch\n",
      "hoc\n",
      "iba\n",
      "gbm\n",
      "sun\n",
      "war\n",
      "mvv\n",
      "pap\n",
      "ary\n",
      "kxi\n",
      "csb\n",
      "pag\n",
      "cos\n",
      "rif\n",
      "kek\n",
      "krc\n",
      "aii\n",
      "ban\n",
      "ssw\n",
      "tvl\n",
      "mfe\n",
      "tah\n",
      "bvy\n",
      "bcl\n",
      "hnj\n",
      "nau\n",
      "nst\n",
      "afb\n",
      "quc\n",
      "min\n",
      "tmw\n",
      "mad\n",
      "bjn\n",
      "mai\n",
      "cjy\n",
      "got\n",
      "hsn\n",
      "gan\n",
      "tzl\n",
      "dws\n",
      "ldn\n",
      "afh\n",
      "sgs\n",
      "krl\n",
      "vep\n",
      "rue\n",
      "tly\n",
      "mic\n",
      "ext\n",
      "izh\n",
      "sma\n",
      "jam\n",
      "cmo\n",
      "mwl\n",
      "kpv\n",
      "koi\n",
      "ike\n",
      "\\N\n",
      "mnc\n",
      "aoz\n",
      "otk\n",
      "kas\n",
      "aln\n",
      "akl\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "negative_sentences = []\n",
    "for ln in lang.cmn.unique():\n",
    "    if ln in selected_langs:\n",
    "        langs = lang.loc[lang.cmn == ln].iloc[:50000,-1].tolist()\n",
    "        X.extend(langs)\n",
    "        Y.extend([ln] * len(langs))\n",
    "    elif ln in special_langs:\n",
    "        langs = lang.loc[lang.cmn == ln].iloc[:10000,-1].tolist()\n",
    "        X.extend(langs)\n",
    "        Y.extend([ln] * len(langs))\n",
    "    else:\n",
    "        print(ln)\n",
    "        negative_sentences.extend(lang.loc[lang.cmn == ln].iloc[-300:,-1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(negative_sentences)\n",
    "Y.extend(['OTHER'] * len(negative_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ind', 'ind', 'ind', 'ind', 'ind', 'ind', 'ind', 'ind', 'ind', 'ind']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def simple_textcleaning_language_detection(string):\n",
    "    string = re.sub('[^A-Za-z ]+', ' ', unidecode(string))\n",
    "    string = filter(None, string.split())\n",
    "    string = [y.strip() for y in string if len(y) > 1]\n",
    "    return ' '.join(string).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = ''\n",
    "for i in [i for i in os.listdir('crawler') if i.find('isu')>=0]:\n",
    "    with open('crawler/' + i,'r') as fopen:\n",
    "        isu = json.load(fopen)\n",
    "    bm += ' '.join([simple_textcleaning_language_detection(i['summary']) for i in isu if i['language']=='id'])\n",
    "bm = bm.split()\n",
    "new_langs = [' '.join(bm[i:i+4]) for i in range(0, len(bm), 4)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(new_langs)\n",
    "Y.extend(['zlm'] * len(new_langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['OTHER', 'ara', 'ber', 'bul', 'ces', 'cmn', 'dan', 'deu', 'ell',\n",
       "        'eng', 'epo', 'fin', 'fra', 'heb', 'hun', 'ind', 'ita', 'jpn',\n",
       "        'kor', 'lat', 'lit', 'mar', 'mkd', 'nld', 'pol', 'por', 'rus',\n",
       "        'spa', 'srp', 'swe', 'toki', 'tur', 'ukr', 'zlm'], dtype='<U5'),\n",
       " array([ 37910,  10000,  10000,  10000,  10000,  10000,  10000,  10000,\n",
       "         10000,  50000,  10000,  10000,  10000,  10000,  10000,  55036,\n",
       "         10000,  10000,   3687,  10000,  10000,  10000,  10000,  10000,\n",
       "         10000,  10000,  10000,  10000,  10000,  10000,  10000,  10000,\n",
       "         10000, 128849]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('language-detection-data-v4.json','w') as fopen:\n",
    "    fopen.write(json.dumps({'text':X,'label':Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
