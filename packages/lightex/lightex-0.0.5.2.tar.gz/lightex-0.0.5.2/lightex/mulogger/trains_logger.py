from dataclasses import dataclass
from typing import List
from . import AbstractLogger, get_experiment_name, get_project_name
import logging
from pathlib import Path

@dataclass
class TrainsConfig:
    _class_: str = 'TrainsLogger'
    #host: str ="http://localhost"
    #webserver_port: int = 8080
    #apiserver_port: int = 8008
    config_file: str ="./trains.conf" #generated by trains-init, all config here
    '''
    export TRAINS_API_ACCESS_KEY="key_here"
    export TRAINS_API_SECRET_KEY="secret_here"
    export TRAINS_API_HOST="http://localhost:8008"
    def uri(self):
        return f'{self.host}:{self.apiserver_port}'
    '''

    def __post_init__(self):
        self.check()

    def check(self):
        tr_conf = Path(self.config_file)
        assert tr_conf.exists(), f"Trains config file {tr_conf} does not exist"
        #self.config_file = tr_conf

    def get_env(self):
        return [('TRAINS_CONFIG_FILE', self.config_file)
                ]


class TrainsLogger(AbstractLogger):
    name = 'trains'

    def init_task_logger(self):
        self.task = self.trains.Task.init(project_name=self.project_name, task_name=self.experiment_name)
        self.logger = self.task.get_logger()

    def __init__(self, project_name=None, experiment_name=None, config=TrainsConfig()):
        import trains
        self.trains = trains
        config.check()

        self.project_name = get_project_name(project_name)
        self.experiment_name = get_experiment_name(experiment_name)
        self.task = None
        self.logger = None
        self.init_task_logger()

    def start_run(self, expt_id=None): 
        if self.task is None:
            self.init_task_logger()

    def end_run(self): 
        self.task.close()
        self.task = None
        self.logger = None

    def flush(self):
        self.logger.flush()

    def log_text (self, msg, level=logging.INFO, print_console=False, **kwargs):
        self.logger.report_text(self, msg, level=level, print_console=print_console, **kwargs)

    #log any scalar value
    def log_scalar(self, name, value, step):
        self.logger.report_scalar(name, "default", iteration=step, value=value)
        self.flush()

    def log_1d(self, name, value, step, histogram: bool):
        self.logger.report_vector(name, "default_histogram", iteration=step, values=value)
        self.flush()

    def log_2d(self, name, value, step, *args):
        if 'scatter' in args:
            self.logger.report_scatter2d(name, "default2dscatter", iteration=step, values=value)
        else:
            self.logger.report_matrix(name, "default2dmatrix", iteration=step, values=value)
        self.flush()

    def log_3d(self, name, value, step):
        self.logger.report_scatter3d(name, "default3dscatter", iteration=step, values=value)
        self.flush()

    def log_image(self, name, img_matrix, step):
        self.logger.report_image_and_upload(name, "default_image", iteration=step, matrix=img_matrix)
        self.flush()


    #log hyper-parameter
    def log_hparam(self, name, value): 
        self.task.connect({name: value})

    def log_artifacts(self, from_dir, artifact_path):
        raise NotImplementedError
        #trains.OutputModel(self.trains.Task.current_task()).update_weights(link_to_new_model_file_here)





        