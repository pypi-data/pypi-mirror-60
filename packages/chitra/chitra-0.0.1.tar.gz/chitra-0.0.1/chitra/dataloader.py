# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_dataloader.ipynb (unless otherwise specified).

__all__ = ['AUTOTUNE', 'get_basename', 'Clf']

# Cell
import tensorflow as tf
import pathlib
import os

from typing import Union

from .core import remove_dsstore
from .image import read_image, resize_image


# Cell
AUTOTUNE = tf.data.experimental.AUTOTUNE

# Cell
def get_basename(path: tf.string):
    assert isinstance(path, tf.Tensor)
    return tf.strings.split(path, os.path.sep)[-1]

# Cell
class Clf(object):
    def __init__(self):
        self.CLASS_NAMES = None

    def _get_image_list(self, path: str):
        """`path`: pathlib.Path
        Returns: list of images
        """
        assert isinstance(path, str)
        list_images = tf.data.Dataset.list_files(f'{path}/*/*')
        return list_images

    def _process_path(self, path:str, size:Union[None, tuple] = None):
        """`path` :str
        `size`: None or tuple
        """
        assert isinstance(path, (str, tf.Tensor)), f'type of path is {type(path)}, expected type str'
        img = read_image(path)
        img = tf.py_function(resize_image, [img, (160, 160)], [tf.float32])

        label = tf.strings.split(path, os.path.sep)[-2]
        return img, label


    def from_folder(self, path: Union[str, pathlib.Path]):
        """Load dataset from given path.
        Args:
            path: string, path of folder containing dataset.
        Returns: tf.data.Dataset
        """
        assert isinstance(path, (str, pathlib.Path))
        path = pathlib.Path(path)
        remove_dsstore(path)

        list_folders = tf.data.Dataset.list_files(str(path/'*'))
        list_images = self._get_image_list(str(path))

        self.CLASS_NAMES = tuple(get_basename(e).numpy() for e in list_folders)

        data = list_images.map(self._process_path, num_parallel_calls=AUTOTUNE)
        return data