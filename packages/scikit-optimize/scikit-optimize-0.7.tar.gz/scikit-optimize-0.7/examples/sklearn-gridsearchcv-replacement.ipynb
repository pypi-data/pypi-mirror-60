{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn hyperparameter search wrapper\n",
    "\n",
    "Iaroslav Shcherbatyi, Tim Head and Gilles Louppe. June 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example assumes basic familiarity with [scikit-learn](http://scikit-learn.org/stable/index.html). \n",
    "\n",
    "Search for parameters of machine learning models that result in best cross-validation performance is necessary in almost all practical cases to get a model with best generalization estimate. A standard approach in scikit-learn is using `GridSearchCV` class, which takes a set of values for every parameter to try, and simply enumerates all combinations of parameter values. The complexity of such search grows exponentially with the addition of new parameters. A more scalable approach is using `RandomizedSearchCV`, which however does not take advantage of the structure of a search space.\n",
    "\n",
    "Scikit-optimize provides a drop-in replacement for `GridSearchCV`, which utilizes Bayesian Optimization where a predictive model referred to as \"surrogate\" is used to model the search space and utilized to arrive at good parameter values combination as soon as possible.\n",
    "\n",
    "Note: for a manual hyperparameter optimization example, see \"Hyperparameter Optimization\" notebook.\n",
    "\n",
    "## Minimal example\n",
    " \n",
    "A minimal example of optimizing hyperparameters of SVC (Support Vector machine Classifier) is given below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.9873793615441723\n",
      "test score: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_digits(10, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=.25, random_state=0)\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt = BayesSearchCV(\n",
    "    SVC(),\n",
    "    {\n",
    "        'C': (1e-6, 1e+6, 'log-uniform'),  \n",
    "        'gamma': (1e-6, 1e+1, 'log-uniform'),\n",
    "        'degree': (1, 8),  # integer valued parameter\n",
    "        'kernel': ['linear', 'poly', 'rbf'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=32,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced example \n",
    "\n",
    "In practice, one wants to enumerate over multiple predictive model classes, with different search spaces and number of evaluations per class. An example of such search over parameters of Linear SVM, Kernel SVM, and decision trees is given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/david.liu/.virtualenvs/dsmodels/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.9829250185597624\n",
      "test score: 0.9822222222222222\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_digits(10, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# pipeline class is used as estimator to enable \n",
    "# search over different model types\n",
    "pipe = Pipeline([\n",
    "    ('model', SVC())\n",
    "])\n",
    "\n",
    "# single categorical value of 'model' parameter is \n",
    "# sets the model class\n",
    "# We will get ConvergenceWarnings because the problem is not well-conditioned.\n",
    "# But that's fine, this is just an example.\n",
    "linsvc_search = {\n",
    "    'model': [LinearSVC(max_iter=1000)],\n",
    "    'model__C': (1e-6, 1e+6, 'log-uniform'),\n",
    "}\n",
    "\n",
    "# explicit dimension classes can be specified like this\n",
    "svc_search = {\n",
    "    'model': Categorical([SVC()]),\n",
    "    'model__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "    'model__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "    'model__degree': Integer(1,8),\n",
    "    'model__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    pipe,\n",
    "    [(svc_search, 20), (linsvc_search, 16)], # (parameter space, # of evaluations)\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress monitoring and control using `callback` argument of `fit` method\n",
    "\n",
    "It is possible to monitor the progress of BayesSearchCV with an event handler that is called on every step of subspace exploration. For single job mode, this is called on every evaluation of model configuration, and for parallel mode, this is called when n_jobs model configurations are evaluated in parallel.\n",
    "\n",
    "Additionally, exploration can be stopped if the callback returns `True`. This can be used to stop the exploration early, for instance when the accuracy that you get is sufficiently high. \n",
    "\n",
    "An example usage is shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.98\n",
      "Interrupting!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_iter=10, n_jobs=1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "       refit=True, return_train_score=False, scoring=None,\n",
       "       search_spaces={'C': (0.01, 100.0, 'log-uniform')}, verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = load_iris(True)\n",
    "\n",
    "searchcv = BayesSearchCV(\n",
    "    SVC(gamma='scale'),\n",
    "    search_spaces={'C': (0.01, 100.0, 'log-uniform')},\n",
    "    n_iter=10,\n",
    "    cv=3\n",
    ")\n",
    "\n",
    "\n",
    "# callback handler\n",
    "def on_step(optim_result):\n",
    "    score = searchcv.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "    if score >= 0.98:\n",
    "        print('Interrupting!')\n",
    "        return True\n",
    "\n",
    "\n",
    "searchcv.fit(X, y, callback=on_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting total iterations that will be used to explore all subspaces\n",
    "\n",
    "Subspaces in previous examples can further increase in complexity if you add new model subspaces or dimensions for feature extraction pipelines. For monitoring of progress, you would like to know the total number of iterations it will take to explore all subspaces. This can be calculated with `total_iterations` property, as in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = load_iris(True)\n",
    "\n",
    "searchcv = BayesSearchCV(\n",
    "    SVC(),\n",
    "    search_spaces=[\n",
    "        ({'C': (0.1, 1.0)}, 19),  # 19 iterations for this subspace\n",
    "        {'gamma':(0.1, 1.0)}\n",
    "    ],\n",
    "    n_iter=23\n",
    ")\n",
    "\n",
    "print(searchcv.total_iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
