#AUTOGENERATED! DO NOT EDIT! File to edit: dev/00_core.ipynb (unless otherwise specified).

__all__ = ['fix_annotations_format', 'dataset_stats', 'ents_by_label', 'get_label_disparities', 'top_prediction_errors',
           'convert_labels']

#Cell
from collections import defaultdict
import copy
import json
from pathlib import Path
from typing import Dict, List

import srsly
import spacy
from spacy.pipeline import EntityRuler
from spacy.language import Language
from spacy.scorer import Scorer
from .util import filter_overlaps

#Cell
def fix_annotations_format(data):
    for e in data:
        if 'meta' not in e:
            e['meta'] = {}
        if isinstance(e['meta'], list):
            e['meta'] = {
                'source': e['meta']
            }

        for s in e['spans']:
            if 'text' not in s:
                s['text'] = e['text'][s['start']:s['end']]
            s['label'] = s['label'].upper()
    return data

#Cell
def dataset_stats(data: List[Dict[str, object]], serialize=False):
    labels = defaultdict(int)
    examples = defaultdict(list)
    n_examples_no_entities = 0
    for e in data:
        if not e['spans']:
            n_examples_no_entities += 1
            examples['NONE'].append(e)
        else:
            for s in e['spans']:
                label = s['label']
                labels[label] += 1
                examples[label].append(e)

    res = {
        'n_examples': len(data),
        'n_examples_no_entities': n_examples_no_entities,
        'ents_per_type': labels
    }
    if serialize:
        return srsly.json_dumps(res, indent=4)
    else:
        res['examples_with_type'] = examples
        return res

#Cell
def ents_by_label(data: List[Dict[str, object]]):
    """Get a dictionary of unique text spans by label for your data"""
    annotations = defaultdict(set)

    for e in data:
        for s in e['spans']:
            lower_text = s.get('text', e['text'][s['start']:s['end']])
            annotations[s['label']].add(lower_text)

    for label in annotations.keys():
        annotations[label] = sorted(annotations[label])

    return annotations

#Cell
def get_label_disparities(data: List[Dict[str, object]], label1: str, label2: str):
    """Identify annotated spans that have different labels in different examples"""
    annotations = ents_by_label(data)
    if label1 and label2:
        return set(annotations[label1]).intersection(set(annotations[label2]))

#Cell
def top_prediction_errors(nlp: Language, data: List[Dict[str, object]], labels: List[str]=None, k: int = None, exclude_fn=False):
    labels_ = labels or nlp.get_pipe('ner').labels
    texts = [e['text'] for e in data]
    anns = []
    for e in data:
        anns.append({'entities': [(s['start'], s['end'], s['label']) for s in e['spans']]})

    scorer = Scorer()
    errors = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))


    for doc, ann in zip(nlp.pipe(texts), anns):
        cand = set([(e.start_char, e.end_char, e.label_) for e in doc.ents])
        gold = set(ann['entities'])

        fp_diff = cand - gold
        fn_diff = gold - cand

        if fp_diff:
            for fp in fp_diff:
                for gold_ent in gold:
                    if fp[0] == gold_ent[0] and fp[1] == gold_ent[1]:
                        start, end, label = gold_ent
                        false_label = fp[2]
                        text = doc.text[start:end]
                        errors[label][text][false_label] += 1

        if fn_diff and not exclude_fn:
            for fn in fn_diff:
                has_gold_ent = False
                for gold_ent in gold:
                    if fp[0] == gold_ent[0] and fp[1] == gold_ent[1]:
                        has_gold_ent = True

                if not has_gold_ent:
                    start, end, label = fn

                    errors[label][doc.text[start:end]]['NONE'] += 1


    ranked_errors = []

    for label, errors in errors.items():
        for error_text, error_labels in errors.items():
            for error_label, count in error_labels.items():
                ranked_errors.append({'text': error_text, 'true_label': label, 'false_label': error_label, 'count': count})

    ranked_errors = sorted(ranked_errors, key=lambda row: row['count'], reverse=True)
    if k:
        ranked_errors = ranked_errors[:k]
    return ranked_errors

#Cell
def convert_labels(data: List[Dict[str, object]], label_map: Dict[str, str]):
    """Map all occurences of a label in the dataset to a new label."""

    data_ = copy.deepcopy(data)
    for e in data_:
        for s in e['spans']:
            s['label'] = label_map.get(s['label'], s['label'])

    return data_
